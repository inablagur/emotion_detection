{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 – Data Exploration\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "1. Load our train / validation / test splits  \n",
    "2. Confirm data integrity (no missing values, correct columns)  \n",
    "3. Spot-check random examples per emotion  \n",
    "4. Examine class distributions per split (Seaborn plots)  \n",
    "5. (Optional) Inspect text-length distributions  \n",
    "\n",
    "All data files were generated by `scripts/1_load_data.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# — Imports & Setup\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Seaborn styling\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Point to data directory\n",
    "DATA_DIR = Path.cwd().parent / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load CSV Splits via `datasets`\n",
    "\n",
    "We’ll use `load_dataset(\"csv\", …)` to pull in our local files as a DatasetDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 16000 examples [00:00, 267878.27 examples/s]\n",
      "Generating validation split: 2000 examples [00:00, 147629.58 examples/s]\n",
      "Generating test split: 2000 examples [00:00, 113676.02 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'emotion'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'emotion'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'emotion'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# — Load local CSVs\n",
    "ds = load_dataset(\"csv\", data_files={\n",
    "    \"train\": str(DATA_DIR / \"train.csv\"),\n",
    "    \"validation\": str(DATA_DIR / \"validation.csv\"),\n",
    "    \"test\": str(DATA_DIR / \"test.csv\")\n",
    "})\n",
    "\n",
    "# Inspect dataset sizes and columns\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now convert each split into a pandas DataFrame for detailed inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (16000, 2) | Validation: (2000, 2) | Test: (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "# — To pandas\n",
    "df_train = ds[\"train\"].to_pandas()\n",
    "df_val   = ds[\"validation\"].to_pandas()\n",
    "df_test  = ds[\"test\"].to_pandas()\n",
    "\n",
    "print(\"Train:\", df_train.shape, \"| Validation:\", df_val.shape, \"| Test:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Integrity Checks\n",
    "\n",
    "Ensure each DataFrame has:\n",
    "- Exactly two columns: `text` and `label`  \n",
    "- No missing values  \n",
    "- Correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       object\n",
       "emotion    object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0 missing values\n",
      "validation: 0 missing values\n",
      "test: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "# Column names and types\n",
    "display(df_train.dtypes)\n",
    "\n",
    "# Missing values\n",
    "for split, df in [(\"train\", df_train), (\"validation\", df_val), (\"test\", df_test)]:\n",
    "    print(f\"{split}: {df.isna().sum().sum()} missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Result:** No missing values; columns `text` (string) and `emotion` (string) look correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spot-Check Random Examples\n",
    "\n",
    "View random text per emotion from the training set to manually verify quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ANGER ---\n",
      "# i ve been feeling a bit cranky with the kids this week cranky baby whiny year old demanding preschooler so i wanted to stop and remember how blessed i really am\n",
      "# i feel frustrated sometimes with my mac lipsticks when i have to read names or open each of them to select shade\n",
      "# i feeling stressed\n",
      "\n",
      "\n",
      "--- FEAR ---\n",
      "# i can feel the frantic beat of his heart but cookie s voice is surprisingly clear\n",
      "# i feel a little suspicious\n",
      "# i can t help but feeling weird when opening every closet in an apartment that somebody s still living in so i didn t\n",
      "\n",
      "\n",
      "--- JOY ---\n",
      "# i feel im rather innocent in that respect\n",
      "# im feeling quite adventurous and tried out those drinks that i just normally read through the pages of pocketbooks\n",
      "# im feeling much more positive about the impending move\n",
      "\n",
      "\n",
      "--- LOVE ---\n",
      "# i mean fuck i feel like i was way more considerate with customers and concerned about appearance and sanitiation snoozel pm but fine\n",
      "# i remember a couple of years ago i was feeling romantic and dreamy and asked him wonder if we ll celebrate our th anniversary\n",
      "# im so going to end up feeling slutty and be like ah\n",
      "\n",
      "\n",
      "--- SADNESS ---\n",
      "# im feeling so lousy they tried to cheer me up during school time and during choir practice\n",
      "# i feel highly disadvantaged\n",
      "# i feel humiliated to introduce you to my colleagues as my wife\n",
      "\n",
      "\n",
      "--- SURPRISE ---\n",
      "# im feeling extraordinarily dazed and bewildered this arvo for no particular reason and my muscles all hurt even though i dont actually have any\n",
      "# i only feel curious impatient eager and confused\n",
      "# i feel a strange sense of legacy\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_samples = 3  # Number of examples to sample per emotion\n",
    "\n",
    "for emotion in sorted(df_train.emotion.unique()):\n",
    "    print(f\"--- {emotion.upper()} ---\")\n",
    "    samples = df_train[df_train.emotion == emotion].sample(n_samples, random_state=42)\n",
    "    for idx, row in samples.iterrows():\n",
    "        print(f\"# {row.text}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Observation:** No capital letters. Doesn't have any symbols or punctuation marks (including apostrophe); Sometimes just doesn't have apostrophe and somethimes have space wher it should have been (I assume it's the same for the punctuation marks); Some locating mistakes (---LOVE--- has this \"# i mean fuck i feel like i was way more considerate with customers and concerned about appearance and sanitiation snoozel pm but fine\n",
    "\") ; Written not according to grammatic rules sometimes (---ANGER--- \"# i feeling stressed\") ; \n",
    "\n",
    "##TODO: Send this output to the chat and ask him to write an observation about it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_emotion_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
